{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DownloadDigitalGlobeData.ipynb","version":"0.3.2","provenance":[{"file_id":"1nh1u53RM69HhSjFFN8dLzi1I0wxkwMd0","timestamp":1539708053620},{"file_id":"1Wg5fVRbue3wnDKskzcuPxJKNgg-JLngB","timestamp":1539707936305},{"file_id":"1RSxwnm5xxVexX3nZxrGv_vhp-Lxg-HOa","timestamp":1539707850177},{"file_id":"166Em2G7CPhJPdRYAcN2C-sUEO104lH4g","timestamp":1539707665140},{"file_id":"1J1KuXDcpwpnYDwRqkU7eJ6M2KNBydfoN","timestamp":1539707538663}],"collapsed_sections":["zIdK8ljYaTWU","_mYTFK7Wtbuc","ToJoIDk0ihI4"]},"kernelspec":{"name":"python2","display_name":"Python 2"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"zz5mtzecGRqo","colab_type":"code","colab":{}},"cell_type":"code","source":["# Import statements for connecting to google cloud. This should give you a link\n","# for authentication. Click on the link and sign in with your google account\n","# that is connected to the google bucket containing your data.\n","from google.colab import auth\n","from google.cloud import storage\n","auth.authenticate_user()\n","\n","# First, we need to set our project. Replace the assignments below with the\n","# project ID and bucket name to access for your data.\n","project_id = 'humanitarian-tent'\n","bucket_name = 'tent-bucket'\n","!gcloud config set project {project_id}\n","client = storage.Client(project_id)\n","bucket = client.get_bucket(bucket_name)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"IQOPN4KQwtgu","colab_type":"text"},"cell_type":"markdown","source":["# 0. Downloading Digital Globe Data"]},{"metadata":{"id":"zf3357jrZ7Ir","colab_type":"code","colab":{}},"cell_type":"code","source":["# Required import statements. Note that this colab can use any runtime!\n","import urllib2\n","import re\n","from google.cloud import storage\n","from google.cloud.storage import Blob\n","import time"],"execution_count":0,"outputs":[]},{"metadata":{"id":"qC1QDdZ8xTHm","colab_type":"text"},"cell_type":"markdown","source":["## Extracting URLs to Download\n","Digital Globe does not make it easy to download content (even with their export options). Luckily, we can just get all the URLs we need to download and then use a standard request library in python to pull all the data down from their platform. Before we get started, however, we need to be able to first get the URLs, which also implicitly include an access token for a session that you will need to make consecutive requests.\n","\n","\n","\n","1. Go to your library of files\n","2. If your files are in folders, you will have to expand all the folders (do this colab in sections if you have many folders)\n","3.   **On Chrome** Ctrl Click on one of the files you want to pull down and select 'Inspect Element.' This should give you a panel which has a bunch of HTML\n","4. Within the highlighted HTML should be something with a URL starting with something like 'https://services.digitalglobe.com/..../<your_tif_file.tif.''\n","5. Copy paste that URL for the first cell in the WGET section. We will continue on extracting everything in the later section\n","\n"]},{"metadata":{"id":"zIdK8ljYaTWU","colab_type":"text"},"cell_type":"markdown","source":["## Example WGET\n","Now that you have an example URL you want to pull down, let's try to run an example WGET request to pull the file off of Digital Globe and the upload it in to your Google Bucket."]},{"metadata":{"id":"95acpsUVZ5GQ","colab_type":"code","colab":{}},"cell_type":"code","source":["# Example URL - you will have to replace this with the URL you got from your library above\n","url = \"https://services.digitalglobe.com/earthservice/kmlaccess/library/request/205615/4842545/?connectId=9e9c4948-da83-4e7b-a558-0c8a71ac3bb2&DGTOKEN=2ea34dc72e4dd768d419242278259b41cadd3d5733d6f211885a3ea8dc3a7436&requestType=undefined&retrievePath=/content/com/library/9e9c4948-da83-4e7b-a558-0c8a71ac3bb2/103001006758EF00_20669/103001006758EF00_R1C1.tif\"\n","file_name = url.split(\"/\")[-1]"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"638M6s02xbfc","colab":{}},"cell_type":"code","source":["file_name"],"execution_count":0,"outputs":[]},{"metadata":{"id":"VgB6Xysfcw_0","colab_type":"code","colab":{}},"cell_type":"code","source":["resp = urllib2.urlopen(url)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Mw6pfco3em2l","colab_type":"code","colab":{}},"cell_type":"code","source":["resp.info().type"],"execution_count":0,"outputs":[]},{"metadata":{"id":"IVUAcUL3bycD","colab_type":"code","colab":{}},"cell_type":"code","source":["blob = bucket.blob(file_name)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"cwHuBpIgfqMn","colab_type":"code","colab":{}},"cell_type":"code","source":["blob.upload_from_string(resp.read(), content_type=resp.info().type)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ln7D_vHqG-Pc","colab_type":"code","colab":{}},"cell_type":"code","source":["# Ensure we have all the expected data in this folder\n","!gsutil ls gs://{bucket_name}"],"execution_count":0,"outputs":[]},{"metadata":{"id":"_mYTFK7Wtbuc","colab_type":"text"},"cell_type":"markdown","source":["## Scraped URLS\n","Now that we know we can scrape one file from a URL, let's try a whole bunch! Now instead of inspecting a single element and copying that single URL, we are instead going to Ctrl click and select the view page source option. Copy and paste all that HTML code in to a separate file. Then upload it to your drive (in the same folder as this colab)."]},{"metadata":{"id":"Nl_eIBvrzYOB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":105},"outputId":"c995575a-2b5a-4745-c4c5-2e66c30c0934","executionInfo":{"status":"ok","timestamp":1544239676931,"user_tz":480,"elapsed":1308,"user":{"displayName":"Emma .M","photoUrl":"","userId":"02101513255726521887"}}},"cell_type":"code","source":["# We called our HTML output digitalglobe.html but call it whatever you want and\n","# and replace the name and filepath for your file in your drive below\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","dg_url_pattern = r\"https:\\/\\/services.digitalglobe.com\\/\\S+.tif\"\n","# !cd /content/gdrive/My\\ Drive/Colab\\ Notebooks/ && ls\n","with open('/content/gdrive/My Drive/Colab Notebooks/digitalglobe.html', 'rb') as f:\n","  content = '\\n'.join(f.readlines())\n","  matches = re.findall(dg_url_pattern, content)\n","matches = list(set(matches))\n","print(\"There are %d URLS from this source!\" % len(matches))\n","print(\"Sample URL:\")\n","print(matches[0])"],"execution_count":21,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","There are 121 URLS from this source!\n","Sample URL:\n","https://services.digitalglobe.com/earthservice/kmlaccess/library/request/205559/4841200/?connectId=9e9c4948-da83-4e7b-a558-0c8a71ac3bb2&amp;DGTOKEN=2ea34dc72e4dd768d419242278259b41cadd3d5733d6f211885a3ea8dc3a7436&amp;requestType=undefined&amp;retrievePath=/content/com/library/9e9c4948-da83-4e7b-a558-0c8a71ac3bb2/103001006EB13800_20669/103001006EB13800_BROWSE.tif\n"],"name":"stdout"}]},{"metadata":{"id":"ToJoIDk0ihI4","colab_type":"text"},"cell_type":"markdown","source":["## Mass Download"]},{"metadata":{"id":"jTB_Ye0chu6W","colab_type":"code","colab":{}},"cell_type":"code","source":["def upload_file(bucket, token, url):\n","  \"\"\"\n","  Pull down content from the given URL and upload it in to the bucket. Note that\n","  this will upload each file to <tile>/<filename> where filename is the existing\n","  URL extension filename and <tile> is the extracted tile where this file is\n","  taken from\n","  bucket: Google bucket object for uploading\n","  token: The Digital Globe token we extracted in the last section from the most\n","         recent URL\n","  url: The pre-collected Digital Globe URL for the file we are interested in\n","  \"\"\"\n","  file_name = url.split(\"/\")[-1]\n","  url = '%sDGTOKEN=%s&requestType%s' % (url.split('DGTOKEN=')[0], token, url.split('&requestType')[1])\n","  token = recent_url.split('DGTOKEN=')[1].split('&requestType')[0]\n","  directory = file_name.split(\"_\")[0]\n","  resp = urllib2.urlopen(url)\n","  if not resp:\n","    print(\"response empty: %s\" % url)\n","    return\n","  if resp.info().type != 'application/octet-stream':\n","    print(\"response has wrong type: %s\" % url)\n","    return\n","  blob = bucket.blob('%s/%s' % (directory, file_name))\n","  blob.upload_from_string(resp.read(), content_type=resp.info().type)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"whNBLFGJp1YB","colab_type":"code","colab":{}},"cell_type":"code","source":["# Retrieve a recent link with the current session token in it (note if you are\n","# in the same session you can use your existing url or the Digital Globe urls.\n","# Otherwise, repeat the instructions for getting a single URL at the start of\n","# the Example WGET section).\n","recent_url = \"https://services.digitalglobe.com/earthservice/kmlaccess/library/request/205611/4842139/?connectId=9e9c4948-da83-4e7b-a558-0c8a71ac3bb2&DGTOKEN=73a95e654bd51395aa1fcf0be071ac7a3b2160d239c43776f04e087ef6634918&requestType=undefined&retrievePath=/content/com/library/9e9c4948-da83-4e7b-a558-0c8a71ac3bb2/1030010061C87300_20669/1030010061C87300_R8C2.tif\""],"execution_count":0,"outputs":[]},{"metadata":{"id":"vi_DtAZ5p92Q","colab_type":"code","colab":{}},"cell_type":"code","source":["# Parse access from recent url (has to be one whose session is currently running)\n","token = recent_url.split('DGTOKEN=')[1].split('&requestType')[0]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"SyvAV2r8ijaw","colab_type":"code","outputId":"1f2dc434-75ee-470a-9284-a057d3b267f8","colab":{"base_uri":"https://localhost:8080/","height":884}},"cell_type":"code","source":["# Upload our sample urls we collected earlier\n","for i in range(39, 90):\n","  print(\"Processing url at index %d\" % i)\n","  upload_file(bucket, token, sample_urls[i])\n","  time.sleep(1)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Processing url at index 39\n","Processing url at index 40\n","Processing url at index 41\n","Processing url at index 42\n","Processing url at index 43\n","Processing url at index 44\n","Processing url at index 45\n","Processing url at index 46\n","Processing url at index 47\n","Processing url at index 48\n","Processing url at index 49\n","Processing url at index 50\n","Processing url at index 51\n","Processing url at index 52\n","Processing url at index 53\n","Processing url at index 54\n","Processing url at index 55\n","Processing url at index 56\n","Processing url at index 57\n","Processing url at index 58\n","Processing url at index 59\n","Processing url at index 60\n","Processing url at index 61\n","Processing url at index 62\n","Processing url at index 63\n","Processing url at index 64\n","Processing url at index 65\n","Processing url at index 66\n","Processing url at index 67\n","Processing url at index 68\n","Processing url at index 69\n","Processing url at index 70\n","Processing url at index 71\n","Processing url at index 72\n","Processing url at index 73\n","Processing url at index 74\n","Processing url at index 75\n","Processing url at index 76\n","Processing url at index 77\n","Processing url at index 78\n","Processing url at index 79\n","Processing url at index 80\n","Processing url at index 81\n","Processing url at index 82\n","Processing url at index 83\n","Processing url at index 84\n","Processing url at index 85\n","Processing url at index 86\n","Processing url at index 87\n","Processing url at index 88\n","Processing url at index 89\n"],"name":"stdout"}]},{"metadata":{"id":"wilBm72KqUhW","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}