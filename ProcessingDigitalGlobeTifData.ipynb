{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ProcessingDigitalGlobeTifData.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"_6YxTtnQxu0k","colab_type":"text"},"cell_type":"markdown","source":["# 1. Setting Up Colab on the Google VM\n","How to use the Colab interface on a remote Google virtual machine that is mounted with a Google Bucket."]},{"metadata":{"id":"5fGPIyNIxm8-","colab_type":"text"},"cell_type":"markdown","source":["## Initial Set Up   *(only has to be done once per account)*\n","(Locally)\n","1. `gcloud init` (if you haven’t already)\n","2. `gcloud compute config-ssh` (if you haven’t already, create your password)\n","\n","(On VM)\n","0. Start VM (if it isn't already) on the Google VM page and under the connect column, go to the SSH tab and select 'Open in browser window'\n","1. Follow the instructions for installing gcsfuse here https://github.com/GoogleCloudPlatform/gcsfuse/blob/master/docs/installing.md\n","2. Install conda\n","\n",">`wget http://repo.continuum.io/archive/Anaconda3-4.0.0-Linux-x86_64.sh`\n",">`bash Anaconda3-4.0.0-Linux-x86_64.sh`\n","\n",">Note that if this gives you an error involving unpackaging the zip file, try:\n","\n",">`sudo apt-get install bzip2`\n",">`rm -r /home/<your_username>/anaconda3`\n","\n","3. `source ~/.bashrc`\n","4. `conda install jupyter`\n","5. `conda install tornado=4.5.3` (resolving depending issue)\n","6. `pip install jupyter_http_over_ws`\n","7. `pip install requests==2.4.3`\n","8. `jupyter serverextension enable --py jupyter_http_over_ws`\n","9. `conda upgrade ipykernel`\n","\n","*In order to run colab (or any notebook) from a VM, we have to run the notebook from the VM, and then pipe the output of that VM on to our local machine (we'll be using port 8888). Once we do this, we can have a display run 'locally' (either through Jupyter notebook or colab).*\n","\n","## Running the VM on Colab\n","(Locally)\n","1. In your terminal, run:\n","\n",">`gcloud compute ssh --zone us-west1-b dfd-cpu-instance -- -L 8888:localhost:8888`\n","\n",">(replace us-west1-b and dfd-cpu-instance with your VM's region and instance name respectively)\n","\n","(On VM)\n","1. Start VM (if it isn't already) on the Google VM page and under the connect column, go to the SSH tab and select 'Open in browser window' and under the connect column, go to the SSH tab and select 'Open in browser window.' If you are already in the VM, make sure you are in your home directory.\n","3. `mkdir satellite && cd satellite` (we called our data directory satellite but you can call it anything you want)\n","4. Check if there's anything in this directory. If not, run (in the satellite folder): `gcsfuse tent-bucket .`\n","5. In the pop-up terminal, type:\n","`jupyter notebook --NotebookApp.allow_origin='https://colab.research.google.com'  --port=8888 --no-browser`\n","6. Copy and paste link in URL it prints out (it will direct to a jupyter notebook page)\n","7. From here you can directly create/run notebooks, or go to the next step to connect to the colab\n","8. In the colab, go to the runtime option (click the down arrow), connect to 'local' and make sure the port is 8888 (or whatever you set it as in part 6)\n","9. Now you can run the rest of this colab! :)\n"]},{"metadata":{"id":"FK2InX8nxoah","colab_type":"text"},"cell_type":"markdown","source":["# 2. Processing Digital Globe Data in to Image Files\n","Processing our Digital Globe Data, which exists as TIF files in to consumable chunks of images and geo-mapping the correpsonding structures in our labelling data to each output image."]},{"metadata":{"id":"t4T2N2zUwjM6","colab_type":"code","outputId":"fe711320-1f29-4a7a-e3fe-0f5a75c013e7","executionInfo":{"status":"ok","timestamp":1544170477609,"user_tz":480,"elapsed":5543,"user":{"displayName":"Emma .M","photoUrl":"","userId":"02101513255726521887"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"cell_type":"code","source":["# Install necessary imports for processing TIF files\n","!pip install rasterio\n","\n","# Import necessary libraries\n","import base64\n","import json\n","import pandas as pd\n","from PIL import Image\n","from io import BytesIO\n","from collections import defaultdict\n","\n","# import geopandas as gpd\n","# from geopandas import GeoDataFrame\n","import descartes\n","from shapely.geometry import Point\n","import numpy as np\n","\n","from rasterio.io import MemoryFile\n","import rasterio\n","import rasterio.features\n","import rasterio.warp\n","from rasterio.plot import show\n","\n","import random\n","import glob"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Requirement already satisfied (use --upgrade to upgrade): rasterio in ./anaconda3/lib/python3.5/site-packages\n","Requirement already satisfied (use --upgrade to upgrade): affine in ./anaconda3/lib/python3.5/site-packages (from rasterio)\n","Requirement already satisfied (use --upgrade to upgrade): attrs in ./anaconda3/lib/python3.5/site-packages (from rasterio)\n","Requirement already satisfied (use --upgrade to upgrade): snuggs>=1.4.1 in ./anaconda3/lib/python3.5/site-packages (from rasterio)\n","Requirement already satisfied (use --upgrade to upgrade): cligj>=0.5 in ./anaconda3/lib/python3.5/site-packages (from rasterio)\n","Requirement already satisfied (use --upgrade to upgrade): click<8,>=4.0 in ./anaconda3/lib/python3.5/site-packages (from rasterio)\n","Requirement already satisfied (use --upgrade to upgrade): numpy in ./anaconda3/lib/python3.5/site-packages (from rasterio)\n","Requirement already satisfied (use --upgrade to upgrade): click-plugins in ./anaconda3/lib/python3.5/site-packages (from rasterio)\n","Requirement already satisfied (use --upgrade to upgrade): pyparsing in ./anaconda3/lib/python3.5/site-packages (from snuggs>=1.4.1->rasterio)\n","\u001b[33mYou are using pip version 8.1.1, however version 18.1 is available.\n","You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"],"name":"stdout"}]},{"metadata":{"id":"oshB2zsqe2KL","colab_type":"code","colab":{}},"cell_type":"code","source":["# This is the directory of the mounted google bucket\n","GOOGLE_BUCKET_DIR = 'satellite/'\n","\n","# NOTE: I added 'labels' directory before each file now that it is local\n","# and we are storing the geojson rating data here\n","REGION_MAPPINGS = {\n","    'Africa1': {\n","        'qc': GOOGLE_BUCKET_DIR + 'labels/africa1_qcexport_20180906.geojson',\n","        'raw': GOOGLE_BUCKET_DIR + 'labels/africa1_rawtags_20180906.geojson'},\n","    'Africa2': {\n","        'qc': GOOGLE_BUCKET_DIR + 'labels/africa2_qcexport_20180927.geojson',\n","        'raw': GOOGLE_BUCKET_DIR + 'labels/africa2_rawtags_20180927.geojson'},\n","    'Bangladesh': {\n","        'qc': GOOGLE_BUCKET_DIR + 'labels/bangladesh_qcexport_20180906.geojson',\n","        'raw': GOOGLE_BUCKET_DIR + 'labels/bangladesh_rawtags_20180906.geojson'},\n","    'WesternAsia': {\n","        'qc': GOOGLE_BUCKET_DIR + 'labels/westernAsia_qcexport_20180906.geojson',\n","        'raw': GOOGLE_BUCKET_DIR + 'labels/westernAsia_rawtags_20180906.geojson'}\n","}\n","\n","COLORS = {'UNHCR Tent': 'r',\n","          'Administrative Structure': 'm',\n","          'Round Earthen Structure': 'c',\n","          'Other Tent': 'y'}\n","\n","CHIP_URL_PREFIX = 'https://s3.amazonaws.com/explorationlab/chips/'"],"execution_count":0,"outputs":[]},{"metadata":{"id":"9kjRhk6Ywwrg","colab_type":"code","colab":{}},"cell_type":"code","source":["def get_features(filepath, region):\n","  \"\"\"\n","  Featurize datasets (QC and Raw) according to the following schema from the\n","  stored json object. Note that we:\n","    1) Ignore the metadata tags and only use the 'feature tag'\n","    2) Expand the geography tag within the feature tag to 'latitude',\n","       'longitude', and 'coordinate_type' keys, in addition to the raw geojson\n","    3) Convert date features to pandas Timestamp and confidence score to float\n","\n","  QC datasets\n","  id: unique identifier\n","  label: name for the feature type\n","  score: the CrowdRank confidence score of the assigned attribute, relative to other tags in the dataset. (floating point 0-1 with 0=no confidence, 1= fully confident)\n","  agreement: number of other taggers who placed the same tag type on this point\n","  chip_url: link to a .jpg image chip hosted on aws with the identified feature in the center of the image\n","  timestamp: Date/time in GMT of the last QC batch\n","  acquisition_date: Date the image was collected\n","  sensor: the DigitalGlobe satellite that captured the image\n","  catalog_id: DigitalGlobe identifier for the image strips collected by our satellites\n","  map_id: unique identifier for each lattice cell across the imagery\n","\n","  Raw tags\n","  id: unique identifier\n","  tagger_id: unique identifier of the user\n","  map_view_id: not too helpful for you, but I can use this to link back to another table in the database for the map/image seen by the crowd\n","  type_id: database tag for the feature type\n","  label: name for the feature type\n","  timestamp: time in GMT that tag was placed\n","  \"\"\"\n","  with open(filepath) as f:\n","    content = f.read()\n","  obj = json.loads(content)\n","  data = defaultdict(list)\n","  for x in obj['features']:\n","    data['latitude'].append(x['geometry']['coordinates'][1])\n","    data['longitude'].append(x['geometry']['coordinates'][0])\n","    data['coordinate_type'].append(x['geometry']['type'])\n","    for key in x['properties'].keys():\n","      if key == 'acquisition_date' or key == 'timestamp':\n","        data[key].append(pd.Timestamp(x['properties'][key]))\n","      elif key == 'score':\n","        data[key].append(float(x['properties'][key]))\n","      elif key == 'chip_url':\n","        data[key].append(x['properties'][key].replace(CHIP_URL_PREFIX, ''))\n","      else:\n","        data[key].append(x['properties'][key])\n","  df = pd.DataFrame.from_dict(dict(data))\n","  df['region'] = region\n","  # Clean data a little - group all 'Other Tent ...' together in an 'Other' category\n","  df['label'] = df['label'].apply(lambda x: 'Other Tent' if x.startswith('Other Tent') else x)\n","  return df"],"execution_count":0,"outputs":[]},{"metadata":{"id":"kns-kKdwwzcf","colab_type":"code","colab":{}},"cell_type":"code","source":["def lonlat2xy(lon_in, lat_in, lon1, lon2, lat1, lat2, w, h):\n","  \"\"\"Simple function to calcualte x/y coordinates based on lon/lat coordinate\"\"\"\n","  x = w * (lon_in - lon1) / (lon2 - lon1)\n","  y = h * (lat_in - lat1) / (lat2 - lat1)\n","  return x, y\n","\n","def xy2lonlat(x_in, y_in, lon1, lon2, lat1, lat2, w, h):\n","  \"\"\"Simple function to calcualte lat/lon coordinates based on x/y coordinate\"\"\"\n","  lon = lon1 + (lon2 - lon1) * x_in / w\n","  lat = lat1 + (lat2 - lat1) * y_in / h\n","  return lon, lat"],"execution_count":0,"outputs":[]},{"metadata":{"id":"QVWFX62yw2uD","colab_type":"code","colab":{}},"cell_type":"code","source":["def get_cropped_images(tif_path, labels, xcrop, ycrop):\n","  \"\"\"\n","  Output image crops and corresponding labels for a given tif file and all\n","  labels.\n","  \n","  tif_path: path to the tif file we want to get images out of\n","  labels: pandas dataframe containing the tomnod data ratings file (processed\n","          in get_features method above)\n","  xcrop: width of desired crop (geospatial)\n","  ycrop: height of desired crop (geospatial)\n","  \"\"\"\n","  with rasterio.open(tif_path) as dataset:\n","    \n","    # Read the dataset's valid data mask as a ndarray.\n","    mask = dataset.dataset_mask()\n","    \n","    big_lon1, big_lat1 = 0, 0\n","    big_lon2, big_lat2 = 0, 0\n","    \n","    # Extract feature shapes and values from the array.\n","    for geom, val in rasterio.features.shapes(\n","            mask, transform=dataset.transform):\n","\n","      # Transform shapes from the dataset's own coordinate\n","      # reference system to CRS84 (EPSG:4326).\n","      geom = rasterio.warp.transform_geom(\n","          dataset.crs, 'EPSG:4326', geom, precision=10)\n","\n","      # Get coordinates from the dataset\n","      [big_lon1, big_lat1] = geom['coordinates'][0][0]\n","      [big_lon2, big_lat2] = geom['coordinates'][0][2]\n","    \n","    w, h = dataset.profile['width'], dataset.profile['height']\n","    # Assign crop sizes according to the resolution\n","    lon_crop = xcrop/w * (big_lon2 - big_lon1)\n","    lat_crop = ycrop/h * (big_lat2 - big_lat1)\n","\n","    # Flip dimension order to have channel last instead of first\n","    big_im = np.transpose(dataset.read(), (1,2,0))\n","  \n","  ims, labels_crops = [], []\n","  \n","  # Iterate through each crop grid and calculate its labels\n","  for x1 in range(0, w, xcrop):\n","    for y1 in range(0, h, ycrop):\n","      \n","      # Calculate lat/lon boundaries for crop\n","      lon1, lat1 = xy2lonlat(\n","          x1, y1, big_lon1, big_lon2, big_lat1, big_lat2, w, h)\n","      lon2, lat2 = lon1 + lon_crop, lat1 + lat_crop\n","      min_lon, max_lon = min(lon1, lon2), max(lon1, lon2)\n","      min_lat, max_lat = min(lat1, lat2), max(lat1, lat2)\n","\n","      # Get all structures within this range and create the label\n","      labels_crop = labels[(labels.latitude  > min_lat) &\n","                           (labels.latitude  < max_lat) & \n","                           (labels.longitude > min_lon) &\n","                           (labels.longitude < max_lon)]\n","      labels_crop['tile_min_lat'] = big_lat1\n","      labels_crop['tile_max_lat'] = big_lat2\n","      labels_crop['tile_min_lon'] = big_lon1\n","      labels_crop['tile_max_lon'] = big_lon2\n","      labels_crop['min_lat'], labels_crop['max_lat'] = min_lat, max_lat\n","      labels_crop['min_lon'], labels_crop['max_lon'] = min_lon, max_lon\n","      labels_crop['x'], labels_crop['y'] = lonlat2xy(\n","          labels_crop.longitude, labels_crop.latitude, lon1, lon2, lat1, lat2,\n","          xcrop, ycrop)\n","      \n","      # Create the cropped images\n","      im = big_im[y1:y1+ycrop, x1:x1+xcrop, :]\n","      ims.append(im)\n","      labels_crops.append(labels_crop)\n","    \n","  return ims, labels_crops"],"execution_count":0,"outputs":[]},{"metadata":{"id":"8ZlHW1-Xw4nX","colab_type":"code","colab":{}},"cell_type":"code","source":["def upload_crops(ims, labels_crops, tif_prefix, dest=''):\n","  \"\"\"\n","  Upload an array of image and labels for crops to a filepath\n","  ims: array of images\n","  labels_crops: array of pandas dataframes containing labels w.r.t each image\n","  tf_prefix: tif_id to store the images under\n","  \"\"\"\n","  indices = [i for i in range(len(labels_crops)) if not labels_crops[i].empty]\n","  if len(indices) == 0:\n","    return\n","  region = labels_crops[indices[0]].region.unique()[0]\n","  for i in indices:\n","    png_filename = '%s%s/%s_%d.png' % (dest, region, tif_prefix, i)\n","    print('Outputting: %s' % png_filename)\n","    img = ims[i]\n","    if img.shape[-1] == 1:\n","      img = np.squeeze(np.stack((img,) * 3, -1)) \n","    Image.fromarray(img.astype('uint8')).save(png_filename)\n","    csv_filename = '%s%s/%s_%d.csv' % (dest, region, tif_prefix, i)\n","    labels_crops[i].to_csv(csv_filename, encoding='utf-8')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"NLMRfDoNw5qp","colab_type":"code","outputId":"c884ab95-ec1b-48d0-8c69-249725b40323","executionInfo":{"status":"ok","timestamp":1544170827966,"user_tz":480,"elapsed":263180,"user":{"displayName":"Emma .M","photoUrl":"","userId":"02101513255726521887"}},"colab":{"base_uri":"https://localhost:8080/","height":867}},"cell_type":"code","source":["# For the project, we copied all the code above and then moved all the code\n","# below under the main function (commented out below). This allowed us to run\n","# a script processing on all examples remotely and detach the thread.\n","# Note that this can also be adapted to run on the colab (although this may take\n","# significantly slower as the .tif files will not be mounted on the file system)\n","\n","# if __name__ == \"__main__\":\n","qc = pd.DataFrame()\n","for region in REGION_MAPPINGS.keys():\n","  if len(qc) == 0:\n","    qc = get_features(REGION_MAPPINGS[region]['qc'], region)\n","  else:\n","    qc = qc.append(get_features(REGION_MAPPINGS[region]['qc'], region))\n","all_tifs = glob.glob(GOOGLE_BUCKET_DIR + '*/*.tif')\n","failed_indices = []\n","CROP_SIZE = 500\n","for i in range(10):\n","  tif = all_tifs[i]\n","  print(\"Processing index %d, tile %s\" % (i,tif))\n","  tif_prefix = (tif.split('/')[-1]).split('.')[0]\n","#   try:\n","  ims, labels_crops = get_cropped_images(tif, qc, CROP_SIZE, CROP_SIZE)\n","  upload_crops(ims, labels_crops, tif_prefix)\n","#   except:\n","#     failed_indices.append(i)\n","print(\"Failed indices:\")\n","for idx in failed_indices:\n","  print(idx)"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Processing index 0, tile satellite/10200100058D0600/10200100058D0600_BROWSE.tif\n"],"name":"stdout"},{"output_type":"stream","text":["/home/mekmarriott/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:59: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n","/home/mekmarriott/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:60: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n","/home/mekmarriott/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:61: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n","/home/mekmarriott/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:62: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n","/home/mekmarriott/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:63: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n","/home/mekmarriott/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:64: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n","/home/mekmarriott/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py:67: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"],"name":"stderr"},{"output_type":"stream","text":["Outputting: Africa1/10200100058D0600_BROWSE_2.png\n","Outputting: Africa1/10200100058D0600_BROWSE_3.png\n","Outputting: Africa1/10200100058D0600_BROWSE_17.png\n","Outputting: Africa1/10200100058D0600_BROWSE_18.png\n","Processing index 1, tile satellite/10200100058D0600/10200100058D0600_R10C1.tif\n","Processing index 2, tile satellite/10200100058D0600/10200100058D0600_R10C2.tif\n","Processing index 3, tile satellite/10200100058D0600/10200100058D0600_R10C3.tif\n","Processing index 4, tile satellite/10200100058D0600/10200100058D0600_R11C1.tif\n","Processing index 5, tile satellite/10200100058D0600/10200100058D0600_R11C2.tif\n","Processing index 6, tile satellite/10200100058D0600/10200100058D0600_R11C3.tif\n","Processing index 7, tile satellite/10200100058D0600/10200100058D0600_R12C1.tif\n","Processing index 8, tile satellite/10200100058D0600/10200100058D0600_R12C2.tif\n","Processing index 9, tile satellite/10200100058D0600/10200100058D0600_R12C3.tif\n","Failed indices:\n"],"name":"stdout"}]}]}